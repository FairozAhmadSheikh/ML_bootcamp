{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81072f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377424fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_disease=pd.read_csv(\"heart_disease.csv\")\n",
    "heart_disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebf54de",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = heart_disease.drop(\"target\", axis=1)\n",
    "y = heart_disease[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca77abab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train & test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0a1dea",
   "metadata": {},
   "source": [
    "#  The Baseline: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6590c281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and fit the baseline model\n",
    "baseline_model = LogisticRegression(max_iter=1000)\n",
    "baseline_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff77b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "baseline_preds = baseline_model.predict(X_test)\n",
    "baseline_acc = accuracy_score(y_test, baseline_preds)\n",
    "\n",
    "print(f\"Baseline Accuracy: {baseline_acc * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525e16f4",
   "metadata": {},
   "source": [
    "# Improvement 1: Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5b6eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Re-run Logistic Regression on scaled data\n",
    "scaled_model = LogisticRegression()\n",
    "scaled_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "scaled_preds = scaled_model.predict(X_test_scaled)\n",
    "scaled_acc = accuracy_score(y_test, scaled_preds)\n",
    "\n",
    "print(f\"Scaled Model Accuracy: {scaled_acc * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a39bcb",
   "metadata": {},
   "source": [
    "# Improvement 2: Ensemble Methods (Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a3a7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Random Forest model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "rf_preds = rf_model.predict(X_test)\n",
    "rf_acc = accuracy_score(y_test, rf_preds)\n",
    "\n",
    "print(f\"Random Forest Accuracy: {rf_acc * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3f3ef6",
   "metadata": {},
   "source": [
    "# Improvement 3: Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240bf7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a grid of hyperparameters to search\n",
    "grid = {\n",
    "    \"n_estimators\": [10, 100, 200, 500],\n",
    "    \"max_depth\": [None, 5, 10, 20],\n",
    "    \"min_samples_split\": [2, 4, 6],\n",
    "    \"min_samples_leaf\": [1, 2, 4]\n",
    "}\n",
    "# Fit the tuned model\n",
    "rs_rf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the best version of the model\n",
    "tuned_preds = rs_rf.predict(X_test)\n",
    "tuned_acc = accuracy_score(y_test, tuned_preds)\n",
    "\n",
    "print(f\"Tuned Random Forest Accuracy: {tuned_acc * 100:.2f}%\")\n",
    "print(f\"Best Parameters: {rs_rf.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d76a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# We'll use our best model\n",
    "y_preds = rs_rf.predict(X_test)\n",
    "conf_mat = confusion_matrix(y_test, y_preds)\n",
    "\n",
    "# Plotting using ConfusionMatrixDisplay\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=conf_mat, display_labels=rs_rf.classes_)\n",
    "disp.plot(ax=ax, cmap='Blues', colorbar=False)\n",
    "\n",
    "plt.title(\"Confusion Matrix: Tuned Random Forest\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12035b02",
   "metadata": {},
   "source": [
    "# Comparing Models with ROC Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9875bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "# Get the probability of the positive class\n",
    "baseline_probs = baseline_model.predict_proba(X_test)[:, 1]\n",
    "rf_probs = rf_model.predict_proba(X_test)[:, 1]\n",
    "tuned_rf_probs = rs_rf.predict_proba(X_test)[:, 1]"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
